{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "from min_max_agent import MinMaxAgent\n",
    "from qlearning_agent import QleaningAgent, play_game\n",
    "from tic_tac_toe import TicTacToe, TikTakCounter\n",
    "from mcts_agent import MCTSAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Крестики-нолики -- это, конечно, далеко не го, и обычный альфа-бета поиск с отсечением здесь наверняка может работать идеально вплоть до довольно больших досок. Однако мы всё-таки для этого учебного задания будем реализовывать более практически релевантный метод MCTS -- заодно фактически получится и упражнение на многоруких бандитов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_step(env: TicTacToe):\n",
    "    actions = env.getEmptySpaces()\n",
    "    return random.choice(actions)\n",
    "\n",
    "\n",
    "def update_counter(counter: TikTakCounter, reward):\n",
    "    if reward == 1:\n",
    "        counter.cross += 1\n",
    "    elif reward == -1:\n",
    "        counter.naughts += 1\n",
    "    elif reward == 0:\n",
    "        counter.draw += 1\n",
    "    else:\n",
    "        counter.invalid += 1\n",
    "    counter.tot += 1\n",
    "\n",
    "\n",
    "def play_rand_game(agent, env, counter: TikTakCounter):\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.get_action(env)\n",
    "        _, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            update_counter(counter, reward)\n",
    "            break\n",
    "        action = random_step(env)\n",
    "        _, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            update_counter(counter, reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сыграем в игру со случайным противником"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-342378f2a8fa>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm.tqdm_notebook(range(100)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf2f83c46ef458ca5d9aadc139aa5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross=1 naughts=0 tot=1 draw=0 invalid=0\n",
      "cross=9 naughts=2 tot=11 draw=0 invalid=0\n",
      "cross=14 naughts=7 tot=21 draw=0 invalid=0\n",
      "cross=18 naughts=13 tot=31 draw=0 invalid=0\n",
      "cross=24 naughts=17 tot=41 draw=0 invalid=0\n",
      "cross=32 naughts=19 tot=51 draw=0 invalid=0\n",
      "cross=39 naughts=22 tot=61 draw=0 invalid=0\n",
      "cross=45 naughts=26 tot=71 draw=0 invalid=0\n",
      "cross=50 naughts=30 tot=81 draw=1 invalid=0\n",
      "cross=57 naughts=33 tot=91 draw=1 invalid=0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcs_agent = MCTSAgent(num_rounds=2000)\n",
    "random.seed(1000)\n",
    "counter = TikTakCounter()\n",
    "env = TicTacToe(4, 4, 3)\n",
    "for i in tqdm.tqdm_notebook(range(100)):\n",
    "    env.reset()\n",
    "    play_rand_game(mtcs_agent, env, counter)\n",
    "    if i % 10 == 0:\n",
    "        print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стратегия иногда проигрывает, попробуем увеличить количество игр при построении дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-a61cac3c8d1f>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm.tqdm_notebook(range(10)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2236d98cded9451ea772c63cc1aeb6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross=1 naughts=0 tot=1 draw=0 invalid=0\n",
      "cross=2 naughts=0 tot=2 draw=0 invalid=0\n",
      "cross=3 naughts=0 tot=3 draw=0 invalid=0\n",
      "cross=3 naughts=1 tot=4 draw=0 invalid=0\n",
      "cross=4 naughts=1 tot=5 draw=0 invalid=0\n",
      "cross=5 naughts=1 tot=6 draw=0 invalid=0\n",
      "cross=5 naughts=2 tot=7 draw=0 invalid=0\n",
      "cross=6 naughts=2 tot=8 draw=0 invalid=0\n",
      "cross=7 naughts=2 tot=9 draw=0 invalid=0\n",
      "cross=8 naughts=2 tot=10 draw=0 invalid=0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtcs_agent = MCTSAgent(num_rounds=30_000)\n",
    "random.seed(1000)\n",
    "counter2 = TikTakCounter()\n",
    "env = TicTacToe(4, 4, 3)\n",
    "for i in tqdm.tqdm_notebook(range(10)):\n",
    "    env.reset()\n",
    "    play_rand_game(mtcs_agent, env=env, counter=counter2)\n",
    "    print(counter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Натренеруем Q-learning агента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 58702/100000 [39:52<28:02, 24.54it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0e73884b8dce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_GAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0magent_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     play_game(env, None, agent_q, counter2,\n\u001b[0m\u001b[1;32m      8\u001b[0m                     True, False, verbose=False)\n\u001b[1;32m      9\u001b[0m     \u001b[0mcounter2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Doc/made/3_sem/made_adl/hw_2/qlearning_agent.py\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m(env, agent1, agent2, counter, random_crosses, random_naughts, verbose)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0magent1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0magent2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0magent2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Doc/made/3_sem/made_adl/hw_2/qlearning_agent.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, env, reward)\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mmax_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_pi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Doc/made/3_sem/made_adl/hw_2/qlearning_agent.py\u001b[0m in \u001b[0;36mupdate_pi\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_pi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mmax_rew_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_rew_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = TicTacToe(4, 4, 4)\n",
    "agent_q = QleaningAgent(env)\n",
    "counter2 = TikTakCounter(100)\n",
    "N_GAME=00_000\n",
    "for i in tqdm.tqdm(range(N_GAME)):\n",
    "    agent_q.new_game(-1)\n",
    "    play_game(env, None, agent_q, counter2,\n",
    "                    True, False, verbose=False)\n",
    "    counter2.tot += 1\n",
    "    counter2.update_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(counter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сыграем agent_q против mtcs_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game2(agent1, agent2, env, counter: TikTakCounter):\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.get_action(env)\n",
    "        _, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            update_counter(counter, reward)\n",
    "            break\n",
    "        state = env.getHash()\n",
    "        action = agent2.get_next_step(state, env, False)\n",
    "        _, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            update_counter(counter, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe(4, 4, 3)\n",
    "mtcs_agent = MCTSAgent(num_rounds=10_000)\n",
    "counter3 = TikTakCounter()\n",
    "N_GAME=20\n",
    "for i in tqdm.tqdm(range(N_GAME)):\n",
    "    agent_q.new_game(-1)\n",
    "    play_game2(mtcs_agent, agent_q, agent_q, counter3)\n",
    "    counter3.tot += 1\n",
    "    counter3.update_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counter3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
